{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Titanic Dataset by Anna Shen\n",
    "\n",
    "## Introduction\n",
    "This is a Kaggle submission I made for a machine learning class at UC Davis. To learn more about this course, look up BAX 452 or Noah Gift on Github.\n",
    "\n",
    "To start with, I created a Github repository for this submission that you can visit at https://github.com/annaeshen/ml_hw1_titanic.\n",
    "\n",
    "## Dataset\n",
    "The dataset is from this Kaggle (Titanic), at https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "### Data Dictionary\n",
    "Variable / Definition / Key:\n",
    "survival; Survival; 0 = No, 1 = Yes\n",
    "pclass; Ticket class; 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex; Sex\n",
    "Age; Age in years\n",
    "sibsp; # of siblings / spouses aboard the Titanic\n",
    "parch; # of parents / children aboard the Titanic\n",
    "ticket; Ticket number\n",
    "fare; Passenger fare\n",
    "cabin; Cabin number\n",
    "embarked; Port of Embarkation; C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "## Dependencies\n",
    "Importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Now that we have the data loaded, we can check out what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Distribution\n",
    "Let's create a crosstab, or frequency chart, to determine the distribution of age. This helps me figure out the best model selection for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.67</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.83</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.92</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.00</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.00</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.00</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.00</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.00</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.00</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.00</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.50</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51.00</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54.00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58.00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "Age         \n",
       "0.42       1\n",
       "0.67       1\n",
       "0.75       2\n",
       "0.83       2\n",
       "0.92       1\n",
       "1.00       7\n",
       "2.00      10\n",
       "3.00       6\n",
       "4.00      10\n",
       "5.00       4\n",
       "6.00       3\n",
       "7.00       3\n",
       "8.00       4\n",
       "9.00       8\n",
       "10.00      2\n",
       "11.00      4\n",
       "12.00      1\n",
       "13.00      2\n",
       "14.00      6\n",
       "14.50      1\n",
       "15.00      5\n",
       "16.00     17\n",
       "17.00     13\n",
       "18.00     26\n",
       "19.00     25\n",
       "20.00     15\n",
       "20.50      1\n",
       "21.00     24\n",
       "22.00     27\n",
       "23.00     15\n",
       "...      ...\n",
       "44.00      9\n",
       "45.00     12\n",
       "45.50      2\n",
       "46.00      3\n",
       "47.00      9\n",
       "48.00      9\n",
       "49.00      6\n",
       "50.00     10\n",
       "51.00      7\n",
       "52.00      6\n",
       "53.00      1\n",
       "54.00      8\n",
       "55.00      2\n",
       "55.50      1\n",
       "56.00      4\n",
       "57.00      2\n",
       "58.00      5\n",
       "59.00      2\n",
       "60.00      4\n",
       "61.00      3\n",
       "62.00      4\n",
       "63.00      2\n",
       "64.00      2\n",
       "65.00      3\n",
       "66.00      1\n",
       "70.00      2\n",
       "70.50      1\n",
       "71.00      2\n",
       "74.00      1\n",
       "80.00      1\n",
       "\n",
       "[88 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=df['Age'],columns=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at a histogram instead of the clunky table above using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x112cbccc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f41d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age = df[np.isfinite(df['Age'])]['Age']\n",
    "plt.hist(age.values)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the output, Age looks to be gamma distributed. \n",
    "\n",
    "Now, in previewing the data I spotted an NaN. The machine learning model will not be happy with the NaNs so I need to get rid of them. My options are: 1) omit them, or 2) replace them. \n",
    "\n",
    "I'm trying to figure out if omitting these rows will be an issue. If a significant portion of the dataset has NaNs, perhaps simply removing the rows would not be the best idea because it could skew the dataset. Let's see how serious this missing data is by counting the number of rows with NaN in the Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19865319865319866"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_age = df['Age'].isnull().sum()\n",
    "total_rows = df.shape[0]\n",
    "ratio = null_age / total_rows\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! If we omitted all the rows with NaNs in Age, we'd be ignoring 19.9% of the dataset! This is a significant amount to throw out. Instead, I'm going to do some imputation using the gamma distribution since that best resembles the Age data. I will call it something new for feature selection (later).\n",
    "\n",
    "I'm setting a seed so that my work is reproducible, and the seed is my fiance's birthday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       22\n",
       "1       38\n",
       "2       26\n",
       "3       35\n",
       "4       35\n",
       "5      472\n",
       "6       54\n",
       "7        2\n",
       "8       27\n",
       "9       14\n",
       "10       4\n",
       "11      58\n",
       "12      20\n",
       "13      39\n",
       "14      14\n",
       "15      55\n",
       "16       2\n",
       "17     424\n",
       "18      31\n",
       "19     422\n",
       "20      35\n",
       "21      34\n",
       "22      15\n",
       "23      28\n",
       "24       8\n",
       "25      38\n",
       "26     423\n",
       "27      19\n",
       "28     334\n",
       "29     345\n",
       "      ... \n",
       "861     21\n",
       "862     48\n",
       "863    463\n",
       "864     24\n",
       "865     42\n",
       "866     27\n",
       "867     31\n",
       "868    579\n",
       "869      4\n",
       "870     26\n",
       "871     47\n",
       "872     33\n",
       "873     47\n",
       "874     28\n",
       "875     15\n",
       "876     20\n",
       "877     19\n",
       "878    443\n",
       "879     56\n",
       "880     25\n",
       "881     33\n",
       "882     22\n",
       "883     28\n",
       "884     25\n",
       "885     39\n",
       "886     27\n",
       "887     19\n",
       "888    474\n",
       "889     26\n",
       "890     32\n",
       "Name: Age2, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = np.random.RandomState(514)\n",
    "df['Age2'] = df['Age'].apply(lambda x: seed.gamma(df.Age.mean(),\n",
    "                                                   df.Age.std())\n",
    "                             if np.isnan(x) else x)\n",
    "df['Age2'] = df['Age2'].astype(int)\n",
    "df['Age2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Setup\n",
    "Now let's move to setting up my model. First I'll need to select my features, or variables.\n",
    "### Preparation - Feature and Label Selection\n",
    "#### Casting Data Types for New Features\n",
    "Let's cast the data types and name them something new so that I don't get confused with the ones that came with the original dataset.\n",
    "\n",
    "I'm casting Pclass2 as ordinal (first, second, third) and Sex2 as binary (1,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Pclass2'] = df.Pclass.map({1: 'first', 2: 'second', 3: 'third'})\n",
    "df['Sex2'] = df.Sex.map({'male': 1, 'female': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected some features that I think could have an impact on the survival. There are probably better ways to select features, but this is my first assignment and I'm not quite advanced at machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = df[['Pclass','Sex2','SibSp','Parch','Age2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the label, or dependent variable/outcome that we're trying to predict, which is whether they survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a gamma distribution is right skewed, I'm going to normalize it by a log transformation. Log(0) is going to result in NaN though, so any young babies aged less than 1, I will replace with 1 before executing the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.091042\n",
       "1      3.637586\n",
       "2      3.258097\n",
       "3      3.555348\n",
       "4      3.555348\n",
       "5      6.156979\n",
       "6      3.988984\n",
       "7      0.693147\n",
       "8      3.295837\n",
       "9      2.639057\n",
       "10     1.386294\n",
       "11     4.060443\n",
       "12     2.995732\n",
       "13     3.663562\n",
       "14     2.639057\n",
       "15     4.007333\n",
       "16     0.693147\n",
       "17     6.049733\n",
       "18     3.433987\n",
       "19     6.045005\n",
       "20     3.555348\n",
       "21     3.526361\n",
       "22     2.708050\n",
       "23     3.332205\n",
       "24     2.079442\n",
       "25     3.637586\n",
       "26     6.047372\n",
       "27     2.944439\n",
       "28     5.811141\n",
       "29     5.843544\n",
       "         ...   \n",
       "861    3.044522\n",
       "862    3.871201\n",
       "863    6.137727\n",
       "864    3.178054\n",
       "865    3.737670\n",
       "866    3.295837\n",
       "867    3.433987\n",
       "868    6.361302\n",
       "869    1.386294\n",
       "870    3.258097\n",
       "871    3.850148\n",
       "872    3.496508\n",
       "873    3.850148\n",
       "874    3.332205\n",
       "875    2.708050\n",
       "876    2.995732\n",
       "877    2.944439\n",
       "878    6.093570\n",
       "879    4.025352\n",
       "880    3.218876\n",
       "881    3.496508\n",
       "882    3.091042\n",
       "883    3.332205\n",
       "884    3.218876\n",
       "885    3.663562\n",
       "886    3.295837\n",
       "887    2.944439\n",
       "888    6.161207\n",
       "889    3.258097\n",
       "890    3.465736\n",
       "Name: Age2, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age2'] = df['Age2'].replace(0,1)\n",
    "df['Age2'] = np.log(df['Age2'])\n",
    "df['Age2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation - Split the data into train and test\n",
    "For training and test data for my model, I'm going to use an 80/20 train/test split.\n",
    "\n",
    "I'll define the train and test split, and then fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features,label,test_size=.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating the ML Model\n",
    "I'm going to use Random Forest because of the number of categorical variables, it would theoretically make sense. (Where each value of a variable is like a branch coming from the nodes of a tree, for example, Sex branches into Male and Female, Passenger Class branches into First, Second, Third, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "rf_train = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting my predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = rf_train.predict(x_train)\n",
    "predict_test = rf_train.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll see how accurate the predictions are for the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.929775280899\n",
      "Test Accuracy: 0.815642458101\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', metrics.accuracy_score(y_train, predict_train))\n",
    "print('Test Accuracy:', metrics.accuracy_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I got an accuracy of 92.6% on the train (80%), and a 82.1% accuracy on the test (20%). While this isn't super high, at least it implies that it's not overfit since 82.1% is lower than 92.6%.\n",
    "\n",
    "## Analysis\n",
    "Let's take a look at the feature importance.\n",
    "\n",
    "For more on feature importance, I referred to http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1\n",
      "0  Pclass  0.111849\n",
      "1    Sex2  0.320104\n",
      "2   SibSp  0.076324\n",
      "3   Parch  0.062322\n",
      "4    Age2  0.429402\n"
     ]
    }
   ],
   "source": [
    "headers = x_train.columns\n",
    "values = list(zip(x_train.columns, model.feature_importances_))\n",
    "print(pd.DataFrame(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "The features with the highest importances are:\n",
    "Age: 0.45\n",
    "Sex: 0.33\n",
    "Pclass: 0.13\n",
    "\n",
    "This means that Age is the most important determining factor, followed by Sex, followed by Passenger class.\n",
    "\n",
    "Let's also take a look at the confusion matrix to validate our findings. Note that a confusion matrix evaluates the accuracy of model (specifically instances of Type I and Type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 14]\n",
      " [19 50]]\n"
     ]
    }
   ],
   "source": [
    "# source: http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "print(metrics.confusion_matrix(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Predictions\n",
    "Now onto the final predictions of who survived in the Kaggle test dataset for export!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the NaNs again\n",
    "test_df = pd.read_csv('test.csv', header=0)\n",
    "seed = np.random.RandomState(514)\n",
    "test_df['Age2'] = test_df['Age'].apply(lambda x: seed.gamma(test_df.Age.mean(),\n",
    "                                                   test_df.Age.std())\n",
    "                             if np.isnan(x) else x)\n",
    "test_df['Age2'] = test_df['Age2'].astype(int)\n",
    "\n",
    "# casting other features again\n",
    "test_df['Pclass2'] = test_df.Pclass.map({1: 'first', 2: 'second', 3: 'third'})\n",
    "test_df['Sex2'] = test_df.Sex.map({'male': 1, 'female': 2})\n",
    "\n",
    "# defining features and labels again\n",
    "test_features = ['Pclass','Sex2','SibSp','Parch','Age2']\n",
    "\n",
    "# normalizing Age with log transformation again\n",
    "test_df['Age2'] = test_df['Age2'].replace(0,1)\n",
    "test_df['Age2'] = np.log(test_df['Age2'])\n",
    "test_df['Age2']\n",
    "\n",
    "# setting up ml again\n",
    "test_predict_test = rf_train.predict(test_df[test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1\n",
      "0  Pclass  0.111849\n",
      "1    Sex2  0.320104\n",
      "2   SibSp  0.076324\n",
      "3   Parch  0.062322\n",
      "4    Age2  0.429402\n"
     ]
    }
   ],
   "source": [
    "headers = x_train.columns\n",
    "values = list(zip(x_train.columns, model.feature_importances_))\n",
    "print(pd.DataFrame(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = test_df['PassengerId']\n",
    "submission_df={\n",
    "    'PassengerId':test_ids,\n",
    "    'Survived':test_predict_test,\n",
    "}\n",
    "submission=pd.DataFrame(submission_df)\n",
    "submission_file=submission.to_csv('AnnaShenTitanicSubmission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
