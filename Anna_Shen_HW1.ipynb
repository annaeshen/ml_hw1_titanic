{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Titanic Dataset by Anna Shen\n",
    "\n",
    "## Introduction\n",
    "This is a Kaggle submission I made for a machine learning class at UC Davis. To learn more about this course, look up BAX 452 or Noah Gift on Github.\n",
    "\n",
    "To start with, I created a Github repository for this submission that you can visit at https://github.com/annaeshen/ml_hw1_titanic.\n",
    "\n",
    "## Dataset\n",
    "The dataset is from this Kaggle (Titanic), at https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "### Data Dictionary\n",
    "Variable / Definition / Key:\n",
    "survival; Survival; 0 = No, 1 = Yes\n",
    "pclass; Ticket class; 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex; Sex\n",
    "Age; Age in years\n",
    "sibsp; # of siblings / spouses aboard the Titanic\n",
    "parch; # of parents / children aboard the Titanic\n",
    "ticket; Ticket number\n",
    "fare; Passenger fare\n",
    "cabin; Cabin number\n",
    "embarked; Port of Embarkation; C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "## Dependencies\n",
    "Importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Now that we have the data loaded, we can check out what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also remove any NAs from the Embarked column (there's only 2 of these)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Embarked'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Distribution\n",
    "Let's create a crosstab, or frequency chart, to determine the distribution of age. This helps me figure out the best model selection for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.67</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.83</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.92</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.00</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.00</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.00</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.00</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.00</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.00</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44.00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.00</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.50</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.00</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51.00</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.00</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54.00</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58.00</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65.00</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "Age         \n",
       "0.42       1\n",
       "0.67       1\n",
       "0.75       2\n",
       "0.83       2\n",
       "0.92       1\n",
       "1.00       7\n",
       "2.00      10\n",
       "3.00       6\n",
       "4.00      10\n",
       "5.00       4\n",
       "6.00       3\n",
       "7.00       3\n",
       "8.00       4\n",
       "9.00       8\n",
       "10.00      2\n",
       "11.00      4\n",
       "12.00      1\n",
       "13.00      2\n",
       "14.00      6\n",
       "14.50      1\n",
       "15.00      5\n",
       "16.00     17\n",
       "17.00     13\n",
       "18.00     26\n",
       "19.00     25\n",
       "20.00     15\n",
       "20.50      1\n",
       "21.00     24\n",
       "22.00     27\n",
       "23.00     15\n",
       "...      ...\n",
       "44.00      9\n",
       "45.00     12\n",
       "45.50      2\n",
       "46.00      3\n",
       "47.00      9\n",
       "48.00      9\n",
       "49.00      6\n",
       "50.00     10\n",
       "51.00      7\n",
       "52.00      6\n",
       "53.00      1\n",
       "54.00      8\n",
       "55.00      2\n",
       "55.50      1\n",
       "56.00      4\n",
       "57.00      2\n",
       "58.00      5\n",
       "59.00      2\n",
       "60.00      4\n",
       "61.00      3\n",
       "62.00      3\n",
       "63.00      2\n",
       "64.00      2\n",
       "65.00      3\n",
       "66.00      1\n",
       "70.00      2\n",
       "70.50      1\n",
       "71.00      2\n",
       "74.00      1\n",
       "80.00      1\n",
       "\n",
       "[88 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=train_df['Age'],columns=\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at a histogram instead of the clunky table above using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1117d4208>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10728a128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age = train_df[np.isfinite(train_df['Age'])]['Age']\n",
    "plt.hist(age.values)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the output, Age looks to be gamma distributed. \n",
    "\n",
    "Now, in previewing the data I spotted an NaN. The machine learning model will not be happy with the NaNs so I need to get rid of them. My options are: 1) omit them, or 2) replace them. \n",
    "\n",
    "I'm trying to figure out if omitting these rows will be an issue. If a significant portion of the dataset has NaNs, perhaps simply removing the rows would not be the best idea because it could skew the dataset. Let's see how serious this missing data is by counting the number of rows with NaN in the Age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19910011248593926"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_age = train_df['Age'].isnull().sum()\n",
    "total_rows = train_df.shape[0]\n",
    "ratio = null_age / total_rows\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! If we omitted all the rows with NaNs in Age, we'd be ignoring 19.9% of the dataset! This is a significant amount to throw out. Instead, I'm going to do some imputation using the gamma distribution since that best resembles the Age data. I will call it something new for feature selection (later).\n",
    "\n",
    "I'm setting a seed so that my work is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       22\n",
       "1       38\n",
       "2       26\n",
       "3       35\n",
       "4       35\n",
       "5      470\n",
       "6       54\n",
       "7        2\n",
       "8       27\n",
       "9       14\n",
       "10       4\n",
       "11      58\n",
       "12      20\n",
       "13      39\n",
       "14      14\n",
       "15      55\n",
       "16       2\n",
       "17     422\n",
       "18      31\n",
       "19     420\n",
       "20      35\n",
       "21      34\n",
       "22      15\n",
       "23      28\n",
       "24       8\n",
       "25      38\n",
       "26     421\n",
       "27      19\n",
       "28     333\n",
       "29     344\n",
       "      ... \n",
       "861     21\n",
       "862     48\n",
       "863    461\n",
       "864     24\n",
       "865     42\n",
       "866     27\n",
       "867     31\n",
       "868    576\n",
       "869      4\n",
       "870     26\n",
       "871     47\n",
       "872     33\n",
       "873     47\n",
       "874     28\n",
       "875     15\n",
       "876     20\n",
       "877     19\n",
       "878    441\n",
       "879     56\n",
       "880     25\n",
       "881     33\n",
       "882     22\n",
       "883     28\n",
       "884     25\n",
       "885     39\n",
       "886     27\n",
       "887     19\n",
       "888    473\n",
       "889     26\n",
       "890     32\n",
       "Name: Age2, Length: 889, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = np.random.RandomState(514)\n",
    "train_df['Age2'] = train_df['Age'].apply(lambda x: seed.gamma(train_df.Age.mean(),\n",
    "                                                   train_df.Age.std())\n",
    "                             if np.isnan(x) else x)\n",
    "train_df['Age2'] = train_df['Age2'].astype(int)\n",
    "train_df['Age2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Setup\n",
    "Now let's move to setting up my model. First I'll need to select my features, or variables.\n",
    "### Preparation - Feature and Label Casting\n",
    "\n",
    "Let's cast the data types as numbers and name them something new to differentiate them from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['Sex2'] = train_df.Sex.map({'male': 1, 'female': 2})\n",
    "train_df['Embarked2'] = train_df.Embarked.map({'C': 1, 'Q': 2, 'S':3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a gamma distribution is right skewed, I'm going to normalize it by a log transformation. Log(0) is going to result in NaN though, so any young babies aged less than 1, I will replace with 1 before executing the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.091042\n",
       "1      3.637586\n",
       "2      3.258097\n",
       "3      3.555348\n",
       "4      3.555348\n",
       "5      6.152733\n",
       "6      3.988984\n",
       "7      0.693147\n",
       "8      3.295837\n",
       "9      2.639057\n",
       "10     1.386294\n",
       "11     4.060443\n",
       "12     2.995732\n",
       "13     3.663562\n",
       "14     2.639057\n",
       "15     4.007333\n",
       "16     0.693147\n",
       "17     6.045005\n",
       "18     3.433987\n",
       "19     6.040255\n",
       "20     3.555348\n",
       "21     3.526361\n",
       "22     2.708050\n",
       "23     3.332205\n",
       "24     2.079442\n",
       "25     3.637586\n",
       "26     6.042633\n",
       "27     2.944439\n",
       "28     5.808142\n",
       "29     5.840642\n",
       "         ...   \n",
       "861    3.044522\n",
       "862    3.871201\n",
       "863    6.133398\n",
       "864    3.178054\n",
       "865    3.737670\n",
       "866    3.295837\n",
       "867    3.433987\n",
       "868    6.356108\n",
       "869    1.386294\n",
       "870    3.258097\n",
       "871    3.850148\n",
       "872    3.496508\n",
       "873    3.850148\n",
       "874    3.332205\n",
       "875    2.708050\n",
       "876    2.995732\n",
       "877    2.944439\n",
       "878    6.089045\n",
       "879    4.025352\n",
       "880    3.218876\n",
       "881    3.496508\n",
       "882    3.091042\n",
       "883    3.332205\n",
       "884    3.218876\n",
       "885    3.663562\n",
       "886    3.295837\n",
       "887    2.944439\n",
       "888    6.159095\n",
       "889    3.258097\n",
       "890    3.465736\n",
       "Name: Age2, Length: 889, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age2'] = train_df['Age2'].replace(0,1)\n",
    "train_df['Age2'] = np.log(train_df['Age2'])\n",
    "train_df['Age2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature selection, I'm throwing out the ticket_number and cabin_number since they are nearly unique identifiers and won't likely have a nonrandom impact on survival, as well as fare (assuming fare and passenger class are colinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# getting dependencies for feature importance\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# listing all possible features for processing (choosing final features later)\n",
    "features = train_df[['Pclass','Sex2','SibSp','Parch','Age2','Embarked2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the label, or dependent variable/outcome that we're trying to predict, which is whether they survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = train_df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation - Split the data into train and test\n",
    "For feature selection I will be using the entire dataset.\n",
    "\n",
    "I'll define the train and test split, and then fit on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1\n",
      "0     Pclass  0.122825\n",
      "1       Sex2  0.311910\n",
      "2      SibSp  0.040091\n",
      "3      Parch  0.063894\n",
      "4       Age2  0.424558\n",
      "5  Embarked2  0.036722\n"
     ]
    }
   ],
   "source": [
    "# subsetting data into test and train\n",
    "x_pretrain, x_pretest, y_pretrain, y_pretest = train_test_split(features,label,test_size=0,random_state=0)\n",
    "\n",
    "# fitting the model\n",
    "model = ExtraTreesClassifier(n_estimators=5)\n",
    "model.fit(x_pretrain, y_pretrain)\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "headers = x_pretrain.columns\n",
    "values = list(zip(x_pretrain.columns, model.feature_importances_))\n",
    "print(pd.DataFrame(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous model, I'll select the features that came out to be most important as the features for input in my final model.\n",
    "\n",
    "According to the output of the above, the feature importances are: \n",
    "\n",
    "Pclass 0.11 \n",
    "\n",
    "Sex2 0.32 \n",
    "\n",
    "SibSp 0.06 \n",
    "\n",
    "Parch 0.05 \n",
    "\n",
    "Age2 0.41 \n",
    "\n",
    "Embarked2 0.04\n",
    " \n",
    "I've decided to throw out Embarked2, SibSp, and Parch. Now I will proceed to build the model using these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_features = train_df[['Pclass','Sex2','Age2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating the Final ML Model\n",
    "I'm going to use Random Forest because the number of categorical variables theoretically look like decision trees. I will proceed to build the model and now use an 85/15 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(final_features,label,test_size=.15,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "rf_model = model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting my predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_train = rf_model.predict(x_train)\n",
    "predict_validation = rf_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll see how accurate the predictions are for the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.912582781457\n",
      "Validation Accuracy: 0.731343283582\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:', metrics.accuracy_score(y_train, predict_train))\n",
    "print('Validation Accuracy:', metrics.accuracy_score(y_validation, predict_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I got an accuracy of 91% on the train (85%), and a 73% accuracy on the validation (15%). While this isn't super high, at least it implies that it's probably not overfit either.\n",
    "\n",
    "## Analysis\n",
    "Let's take a look at the feature importances of the final model.\n",
    "\n",
    "For more on feature importance, I referred to http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1\n",
      "0  Pclass  0.139910\n",
      "1    Sex2  0.365732\n",
      "2    Age2  0.494358\n"
     ]
    }
   ],
   "source": [
    "headers = x_train.columns\n",
    "values = list(zip(x_train.columns, model.feature_importances_))\n",
    "print(pd.DataFrame(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "The features with the highest importances are:\n",
    "Age: 0.46\n",
    "Sex: 0.39\n",
    "Pclass: 0.14\n",
    "\n",
    "This means that Age is the most important determining factor, followed by Sex, followed by Passenger class.\n",
    "\n",
    "Let's also take a look at the confusion matrix to validate our findings. Note that a confusion matrix evaluates the accuracy of model (specifically instances of Type I and Type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63 17]\n",
      " [19 35]]\n"
     ]
    }
   ],
   "source": [
    "# source: http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "print(metrics.confusion_matrix(y_validation, predict_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Predictions\n",
    "Now onto the final predictions of who survived in the Kaggle test dataset for export!\n",
    "\n",
    "I'll need to redo any transformations onto the test.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the NaNs again\n",
    "test_df = pd.read_csv('test.csv', header=0)\n",
    "\n",
    "seed = np.random.RandomState(514)\n",
    "\n",
    "# imputing ages again\n",
    "test_df['Age2'] = test_df['Age'].apply(lambda x: seed.gamma(test_df.Age.mean(),\n",
    "                                                   test_df.Age.std())\n",
    "                             if np.isnan(x) else x)\n",
    "test_df['Age2'] = test_df['Age2'].astype(int)\n",
    "\n",
    "# normalizing Age with log transformation again\n",
    "test_df['Age2'] = test_df['Age2'].replace(0,1)\n",
    "test_df['Age2'] = np.log(test_df['Age2'])\n",
    "\n",
    "# casting other features again\n",
    "test_df['Sex2'] = test_df.Sex.map({'male': 1, 'female': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up ml again \n",
    "predict_test = rf_model.predict(test_df[['Pclass','Sex2','Age2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_df['PassengerId']\n",
    "submission_df={\n",
    "    'PassengerId':test_ids,\n",
    "    'Survived':predict_test,\n",
    "}\n",
    "submission=pd.DataFrame(submission_df)\n",
    "submission_file=submission.to_csv('AnnaShenTitanicSubmission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
